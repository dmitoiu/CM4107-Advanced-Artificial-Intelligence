{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------\n",
    "### Darie-Dragos Mitoiu - 1905367\n",
    "### CM4107 Advanced Artificial Intelligence\n",
    "### Artificial Neural Network and K-Nearest Neighbour Hybrid v1.0.0 26/10/2020\n",
    "### A jupyter notebook for an artificial neural network and a k-nearest neighbour hybrid\n",
    "### -----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from __future__ import division # backward compatibility for python2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import operator\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seaborn style\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting numpy seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training file name\n",
    "train_file = \"data/mnist_train.csv\"\n",
    "# The testing file name\n",
    "test_file = \"data/mnist_test.csv\"\n",
    "\n",
    "# Set the number of input nodes\n",
    "input_nodes = 784\n",
    "# Set the number of hidden nodes\n",
    "hidden_nodes = 200\n",
    "# Set the number of output nodes\n",
    "output_nodes = 10\n",
    "\n",
    "# Set the epochs number\n",
    "epochs = 10\n",
    "# Set the batch size number\n",
    "batch_size = 1\n",
    "# Set the learning rate number\n",
    "learning_rate = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training dataset\n",
    "df_orig_train = pd.read_csv(train_file, header=None)\n",
    "# Read the testing dataset\n",
    "df_orig_test = pd.read_csv(test_file, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Training Data Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records in the mnist training dataset is:  60000\n",
      "The number of columns in the mnist training dataset is:  785\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of records in the mnist training dataset is: \",df_orig_train.shape[0])\n",
    "print(\"The number of columns in the mnist training dataset is: \", df_orig_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 785 entries, 0 to 784\n",
      "dtypes: int64(785)\n",
      "memory usage: 359.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Show training dataset relevant information\n",
    "df_orig_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
       "0    5    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    4    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    9    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of the training dataset\n",
    "df_orig_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Testing Data Insight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 785 entries, 0 to 784\n",
      "dtypes: int64(785)\n",
      "memory usage: 59.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Show testing dataset relevant information\n",
    "df_orig_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
       "0    7    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    2    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    1    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    4    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the head of the testing dataset\n",
    "df_orig_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Training Data Frame Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "y_train_all =  pd.get_dummies(df_orig_train[0]).values\n",
    "X_train_all = df_orig_train.drop(0, axis = 1).values\n",
    "print(y_train_all.shape)\n",
    "print(X_train_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Testing Data Frame Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "y_test_all =  pd.get_dummies(df_orig_test[0]).values\n",
    "X_test_all = df_orig_test.drop(0, axis = 1).values\n",
    "print(y_test_all.shape)\n",
    "print(X_test_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 10)\n",
      "(1500, 784)\n",
      "(1500, 10)\n",
      "(100, 10)\n",
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "# Select smaller samples of the train and test datasets\n",
    "train_sample_size = 1500  # choosing a smaller sample instead of the entire dataset\n",
    "random_indices = np.random.choice(range(len(y_train_all)), train_sample_size, replace = False)\n",
    "\n",
    "X_train = X_train_all[random_indices]\n",
    "y_train = y_train_all[random_indices]\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "#preprocessing steps\n",
    "X_train = (X_train / 255.0 * 0.99) + 0.01\n",
    "y_train = y_train + 0.01\n",
    "y_train = np.where(y_train != 1.01, y_train, 0.99)\n",
    "print(y_train.shape)\n",
    "\n",
    "test_sample_size = 100 \n",
    "random_test_indices = np.random.choice(range(len(y_test_all)), test_sample_size, replace = False)\n",
    "X_test = X_test_all[random_test_indices]\n",
    "y_test = y_test_all[random_test_indices]\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_test = (X_test / 255.0 * 0.99) + 0.01\n",
    "y_test = y_test + 0.01\n",
    "y_test = np.where(y_test != 1.01, y_test, 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(predictions, targets):\n",
    "    \"\"\"\n",
    "    Calculates mean squared error of a model's predictions.\n",
    "    \"\"\"\n",
    "    N=targets.size\n",
    "    mse = ((targets - predictions) **2).sum() / (2*N)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of a model's predictions.\n",
    "    \"\"\"\n",
    "    prediction_labels = np.argmax(predictions, axis=1)\n",
    "    target_labels = np.argmax(targets, axis=1)\n",
    "    predictions_correct = (prediction_labels == target_labels.round())\n",
    "    accuracy = predictions_correct.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "    def backward(self, inputs):\n",
    "        self.output = np.greater(inputs, 0).astype(int) # inputs > 0 then convert bools to int\n",
    "        \n",
    "class Activation_Sigmoid:\n",
    "    def forward(self, x):\n",
    "        return(1 / (1 + np.exp(-x)))\n",
    "    def backward(self, x):\n",
    "        return(x * ( 1 - x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons, learningrate=0.01, activation='sigmoid'):\n",
    "        \n",
    "        self.weights = np.random.normal(0.0, pow(n_inputs, -0.5), (n_inputs, n_neurons))\n",
    "        print(self.weights.shape)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "       \n",
    "        self.lr = learningrate\n",
    "        self.activate=activation  \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.in_values = inputs\n",
    "        self.layer_input = np.dot(inputs , self.weights) + self.biases\n",
    "        self.activation()\n",
    "    \n",
    "    def activation(self):\n",
    "        if self.activate == 'sigmoid':\n",
    "            a = Activation_Sigmoid()\n",
    "            self.layer_output = a.forward(self.layer_input)\n",
    "            \n",
    "           \n",
    "    def del_activation(self):\n",
    "        if self.activate == 'sigmoid':\n",
    "            del_a = Activation_Sigmoid()\n",
    "            self.del_layer_output =  del_a.backward(del_a.forward(self.layer_input))\n",
    "      \n",
    "    def backward(self, delta_in, weights_in, targets=None, output_layer=False):\n",
    "        self.del_activation()\n",
    "        if output_layer:\n",
    "            self.layer_error = self.layer_output - targets\n",
    "            self.layer_delta = self.layer_error * self.del_layer_output\n",
    "        else:          \n",
    "            self.layer_error = np.dot(delta_in, weights_in.T)\n",
    "            self.layer_delta = self.layer_error * self.del_layer_output\n",
    "        \n",
    "    def weight_update(self, prev_layer_output):\n",
    "        # print(\"prev_layer_output.T.shape: \"+str(prev_layer_output.T.shape))\n",
    "        # print(\"self.layer_delta.shape: \"+str(self.layer_delta.shape))\n",
    "        N = self.layer_delta.shape[0]\n",
    "        weights_update = np.dot(prev_layer_output.T, self.layer_delta) / N\n",
    "        # print(weights_update.shape)\n",
    "        self.weights -= self.lr * weights_update\n",
    "        biases_update = np.mean(self.layer_delta, axis=0, keepdims=True)\n",
    "        # print(\"biases_update.shape: \"+ str(biases_update.shape))\n",
    "        # print(\"self.biases.shape: \"+ str(self.biases.shape))\n",
    "        self.biases -= self.lr * biases_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 200)\n",
      "(200, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115913</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111464</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.107237</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103236</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099461</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.044720</td>\n",
       "      <td>0.164667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.044681</td>\n",
       "      <td>0.164667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.044642</td>\n",
       "      <td>0.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.044605</td>\n",
       "      <td>0.165333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.044568</td>\n",
       "      <td>0.166000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_squared_error  accuracy\n",
       "0             0.115913  0.104000\n",
       "1             0.111464  0.104000\n",
       "2             0.107237  0.104000\n",
       "3             0.103236  0.104000\n",
       "4             0.099461  0.104000\n",
       "..                 ...       ...\n",
       "95            0.044720  0.164667\n",
       "96            0.044681  0.164667\n",
       "97            0.044642  0.164000\n",
       "98            0.044605  0.165333\n",
       "99            0.044568  0.166000\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 = Layer_Dense(784, 200) # set the weight matrix dimensions (input nodes x hidden nodes)\n",
    "output = Layer_Dense(200, 10) # set the weight matrix dimensions (hidden nodes x output nodes)\n",
    "\n",
    "# maintain a dataframe to keep track of the network error\n",
    "monitoring = {}\n",
    "monitoring['mean_squared_error'] = []\n",
    "monitoring['accuracy'] = []\n",
    "\n",
    "# iterate and update weights at each epoch\n",
    "for epoch in range(100):\n",
    "    layer1.forward(X_train)\n",
    "    # print('layer1 output \\n' ,layer1.layer_output.shape)\n",
    "    output.forward(layer1.layer_output)\n",
    "    # print('layer output  \\n', output.layer_output.shape)\n",
    "\n",
    "    # train metrics\n",
    "    pred = output.layer_output\n",
    "    mse = mean_squared_error(pred, y_train)\n",
    "    acc = accuracy(output.layer_output, y_train)\n",
    "    monitoring['mean_squared_error'].append(mse)\n",
    "    monitoring['accuracy'].append(acc)\n",
    "\n",
    "    # backprop through the layers \n",
    "    output.backward(None, None, y_train, True)\n",
    "    # print('layer out delta  \\n', output.layer_delta.shape)\n",
    "    layer1.backward(output.layer_delta, output.weights)\n",
    "    # print('layer1 delta  \\n', layer1.layer_delta.shape)\n",
    "\n",
    "    # update all the layer weights\n",
    "    output.weight_update(layer1.layer_output)\n",
    "    # print('layer weights  \\n', output.weights.shape)\n",
    "    layer1.weight_update(X_train)\n",
    "    # print('layer weights  \\n', layer1.weights.shape)\n",
    "\n",
    "monitoring_df = pd.DataFrame(monitoring)   \n",
    "monitoring_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN():\n",
    "    def __init__(self, ouput_layer, hidden_layer, batch_size = 10):\n",
    "        self.output = ouput_layer\n",
    "        self.layer1 = hidden_layer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def batch_input(self, x, y):\n",
    "        for i in range(0, len(x), self.batch_size):\n",
    "            yield (x[i:i + self.batch_size], y[i:i + self.batch_size])\n",
    "\n",
    "    def train(self, x, y, epochs, lr):\n",
    "        self.layer1.lr = lr\n",
    "        self.output.lr = lr\n",
    "\n",
    "        monitoring = {}\n",
    "        monitoring['mean_squared_error'] = []\n",
    "        monitoring['accuracy'] = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for (batch_x, batch_y) in self.batch_input(x, y):\n",
    "                self.layer1.forward(batch_x)\n",
    "                self.output.forward(self.layer1.layer_output)\n",
    "\n",
    "                # backprop through the layers \n",
    "                self.output.backward(None, None, batch_y, True)\n",
    "                self.layer1.backward(self.output.layer_delta, self.output.weights)\n",
    "\n",
    "                # update all the layer weights\n",
    "                self.output.weight_update(self.layer1.layer_output)\n",
    "                self.layer1.weight_update(batch_x)\n",
    "                \n",
    "            pred = self.predict(x)\n",
    "            mse, acc = self.evaluate(pred, y)\n",
    "            monitoring['mean_squared_error'].append(mse)\n",
    "            monitoring['accuracy'].append(acc)\n",
    "\n",
    "        monitoring_df = pd.DataFrame(monitoring)   \n",
    "        return monitoring_df\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.layer1.forward(x)\n",
    "        self.output.forward(self.layer1.layer_output)\n",
    "        return self.output.layer_output\n",
    "\n",
    "    def evaluate(self, predicts, y):\n",
    "        mse = mean_squared_error(predicts, y)\n",
    "        acc = accuracy(predicts, y)\n",
    "        return mse, acc\n",
    "\n",
    "    def test(self, x, y):\n",
    "        monitoring = {}\n",
    "        pred = self.predict(x)\n",
    "        mse, acc = self.evaluate(pred, y)\n",
    "        monitoring['mean_squared_error'] = [mse]\n",
    "        monitoring['accuracy'] = [acc]\n",
    "        return pd.DataFrame(monitoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Within our class we now need code for each of the components of k-NN.\n",
    "#First, let's create a method that will measure the distance between two vectors.\n",
    "def euclidean(instance1, instance2):\n",
    "        '''\n",
    "        Calculates euclidean distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):            \n",
    "            distance += pow((val1 - val2), 2)\n",
    "        \n",
    "        distance = pow(distance, 1/2)\n",
    "             \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "\n",
    "def manhattan(instance1, instance2):\n",
    "        '''\n",
    "        Calculates manhattan distance between two instances of data\n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        distance = 0\n",
    "        for val1, val2 in zip(instance1, instance2):\n",
    "            distance += abs(val1 - val2)      \n",
    "              \n",
    "        return 1 / (1+ distance)\n",
    "    \n",
    "def dot_product(instance1, instance2):\n",
    "        '''\n",
    "        Calculates dot product between two instances \n",
    "        instance1 will be a List of Float values\n",
    "        instance2 will be a List of Float values\n",
    "        length will be an Integer denoting the length of the Lists\n",
    "        '''\n",
    "        return np.dot(instance1, instance2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    X_train, Y_train : list\n",
    "    these consists of the training set feature values and associated class labels\n",
    "    k : int\n",
    "    specify the number of neighbours\n",
    "    sim : literal\n",
    "    specify the name of the similarity metric (e.g. manhattan, eucliedean)\n",
    "    weighted : Boolean\n",
    "    specify the voting strategy as weighted or not weighted by similarity values\n",
    "  \n",
    "    Attributes\n",
    "    -----------  \n",
    "    Results : list\n",
    "      Target and predicted class labels for the test data.    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, X_train, Y_train, k=3, sim=manhattan, weighted=False):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "        if k <= len(self.X_train):\n",
    "            self.k = k # set the k value for neighbourhood size\n",
    "        else:\n",
    "            self.k = len(self.X_train) # to ensure the get_neighbours dont crash\n",
    "    \n",
    "        self.similarity = sim # specify a sim metric that has been pre-defined e.g. manhattan or euclidean\n",
    "        \n",
    "        self.weighted = weighted # boolean to choose between weighted / unweighted majority voting\n",
    "        \n",
    "        #store results from testing \n",
    "        self.results= []\n",
    "        \n",
    "    #With k-NN, we are interested in finding the k number of points with the greatest similarity \n",
    "    # to the the query or test instance.\n",
    "    def get_neighbours(self, test_instance):\n",
    "        '''\n",
    "        Locate most similar neighbours \n",
    "        X_train will be a containing features (Float) values (i.e. your training data)\n",
    "        Y_train will be the corresponding class labels for each instance in X_train\n",
    "        test_instance will be a List of Float values (i.e. a query instance)\n",
    "        '''\n",
    "        similarities = [] # collection to store the similarities to be computed\n",
    "\n",
    "        for train_instance, y in zip(self.X_train, self.Y_train): #for each member of the training set\n",
    "            sim = self.similarity(test_instance, train_instance) #calculate the similarity to the test instance\n",
    "            \n",
    "            similarities.append((y, sim)) #add the actual label of the example and the computed similarity to a collection \n",
    "        #print(distances)\n",
    "        similarities.sort(key = operator.itemgetter(1), reverse = True) #sort the collection by decreasing similarity\n",
    "        neighbours = [] # holds the k most similar neighbours\n",
    "        for x in range(self.k): #extract the k top indices of the collection for return\n",
    "            neighbours.append(similarities[x])\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "    # given the neighbours make a prediction\n",
    "    # the boolean parameter when set to False will use unweighted majority voting; otherwise weighted majority voting\n",
    "    # weighting can be helpful to break any ties in voting\n",
    "    def predict(self, neighbours):\n",
    "        '''\n",
    "        Summarise a prediction based upon weighted neighbours calculation\n",
    "        '''\n",
    "        class_votes = {}\n",
    "        for x in range(len(neighbours)):\n",
    "            response = neighbours[x][0]\n",
    "            if response in class_votes:\n",
    "                class_votes[response] += (1-self.weighted) + (self.weighted * neighbours[x][1]) #if not weighted simply add 1\n",
    "                #class_votes[response] += [1, neighbours[x][1]][weighted == True] \n",
    "              \n",
    "            else:\n",
    "                class_votes[response] = (1-self.weighted) + (self.weighted * neighbours[x][1])\n",
    "                #class_votes[response] = [1, neighbours[x][1]][weighted == True] \n",
    "                \n",
    "        #print(class_votes)\n",
    "        sorted_votes = sorted(class_votes, key = lambda k: (class_votes[k], k), reverse = True)\n",
    "        #print(sorted_votes)\n",
    "        return sorted_votes[0]\n",
    "    \n",
    "    #iterate through all the test data to calculate accuracy\n",
    "    def test(self, X_test, Y_test):\n",
    "        self.results = [] # store the predictions returned by kNN\n",
    "\n",
    "        for test_instance, target_label in zip(X_test, Y_test):\n",
    "            neighbours = self.get_neighbours(test_instance)\n",
    "            predict_label = self.predict(neighbours)\n",
    "            self.results.append([predict_label, target_label])\n",
    "            #print('> predicted = ', result,', actual = ', test_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid():\n",
    "    def __init__(self, ouput_layer, hidden_layer, batch_size = 10):\n",
    "        self.output = ouput_layer\n",
    "        self.layer1 = hidden_layer\n",
    "        self.batch_size = batch_size\n",
    "        self.features = []\n",
    "        self.class_label = []\n",
    "\n",
    "    def batch_input(self, x, y):\n",
    "        for i in range(0, len(x), self.batch_size):\n",
    "            yield (x[i:i + self.batch_size], y[i:i + self.batch_size])\n",
    "\n",
    "    def train(self, x, y, epochs, lr):\n",
    "        self.layer1.lr = lr\n",
    "        self.output.lr = lr\n",
    "\n",
    "        monitoring = {}\n",
    "        monitoring['mean_squared_error'] = []\n",
    "        monitoring['accuracy'] = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for (batch_x, batch_y) in self.batch_input(x, y):\n",
    "                self.layer1.forward(batch_x)\n",
    "                # print('layer1 output \\n' ,layer1.layer_output.shape)\n",
    "                self.output.forward(self.layer1.layer_output)\n",
    "                # print('layer output  \\n', output.layer_output.shape)\n",
    "\n",
    "                # backprop through the layers \n",
    "                self.output.backward(None, None, batch_y, True)\n",
    "                # print('layer out delta  \\n', output.layer_delta.shape)\n",
    "                self.layer1.backward(self.output.layer_delta, self.output.weights)\n",
    "                # print('layer1 delta  \\n', layer1.layer_delta.shape)\n",
    "\n",
    "                # update all the layer weights\n",
    "                self.output.weight_update(self.layer1.layer_output)\n",
    "                # print('layer weights  \\n', output.weights.shape)\n",
    "                self.layer1.weight_update(batch_x)\n",
    "                # print('layer weights  \\n', layer1.weights.shape)\n",
    "            \n",
    "            pred = self.predict(x)\n",
    "            mse, acc = self.evaluate(pred, y)\n",
    "            monitoring['mean_squared_error'].append(mse)\n",
    "            monitoring['accuracy'].append(acc)\n",
    "        \n",
    "        monitoring_df = pd.DataFrame(monitoring)   \n",
    "        return monitoring_df\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.layer1.forward(x)\n",
    "        self.output.forward(self.layer1.layer_output)\n",
    "        return self.output.layer_output\n",
    "\n",
    "    def evaluate(self, predicts, y):\n",
    "        mse = mean_squared_error(predicts, y)\n",
    "        acc = accuracy(predicts, y)\n",
    "        return mse, acc\n",
    "\n",
    "    def test(self, x, y):\n",
    "        self.knn.test(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 200)\n",
      "(200, 10)\n",
      "Pred:  [[0.06226847 0.03628825 0.04210856 ... 0.35427848 0.03645686 0.17584971]\n",
      " [0.10551803 0.05812782 0.1425378  ... 0.04721494 0.08193733 0.05621014]\n",
      " [0.08140993 0.06007074 0.09973767 ... 0.10393678 0.13783874 0.13151303]\n",
      " ...\n",
      " [0.08781152 0.06726742 0.20756234 ... 0.033799   0.06155507 0.09399921]\n",
      " [0.08404087 0.05768056 0.05993967 ... 0.12033355 0.11300735 0.12330531]\n",
      " [0.05872167 0.04367029 0.11248258 ... 0.12084682 0.05331243 0.11324302]]\n",
      "Pred:  [[0.03506434 0.03559416 0.00757645 ... 0.63247896 0.00663559 0.10872184]\n",
      " [0.07561803 0.0322211  0.05361606 ... 0.00716107 0.04795054 0.03015437]\n",
      " [0.03195713 0.06827786 0.0458393  ... 0.03054439 0.44000265 0.14430015]\n",
      " ...\n",
      " [0.09319474 0.00695234 0.05451601 ... 0.00120314 0.03660121 0.07564133]\n",
      " [0.08610593 0.01439844 0.01060102 ... 0.03411033 0.17679303 0.11533628]\n",
      " [0.00571379 0.24038793 0.08567982 ... 0.06673352 0.06079918 0.08848752]]\n",
      "Pred:  [[1.15876166e-02 1.15609801e-02 4.21821479e-03 ... 8.24579577e-01\n",
      "  2.14571882e-03 5.31067973e-02]\n",
      " [2.93773408e-02 7.93586765e-03 2.85906543e-02 ... 3.06378125e-03\n",
      "  2.19524928e-02 1.84654431e-02]\n",
      " [1.40735904e-02 3.68090445e-02 3.17920516e-02 ... 1.23795057e-02\n",
      "  6.25156323e-01 1.18905015e-01]\n",
      " ...\n",
      " [6.32226542e-02 1.10529203e-03 2.74241918e-02 ... 2.40043878e-04\n",
      "  3.45097136e-02 3.64772017e-02]\n",
      " [3.88901298e-02 2.71302292e-03 3.92336954e-03 ... 1.44293935e-02\n",
      "  2.23652892e-01 8.09683197e-02]\n",
      " [1.21678944e-03 2.24875636e-01 6.94719298e-02 ... 4.44304651e-02\n",
      "  6.63066158e-02 5.52904605e-02]]\n",
      "Pred:  [[6.31037000e-03 5.93865422e-03 2.46351528e-03 ... 9.03562293e-01\n",
      "  1.08224773e-03 2.79779045e-02]\n",
      " [1.90146128e-02 3.18991981e-03 1.61696972e-02 ... 1.56315010e-03\n",
      "  1.05464024e-02 1.24177637e-02]\n",
      " [9.46041792e-03 2.55580428e-02 2.55357392e-02 ... 5.95036837e-03\n",
      "  6.89922917e-01 8.77875317e-02]\n",
      " ...\n",
      " [5.53185385e-02 4.32610689e-04 2.03509064e-02 ... 7.92764139e-05\n",
      "  3.00763718e-02 1.88088838e-02]\n",
      " [2.16222585e-02 1.05178268e-03 1.98715152e-03 ... 8.06241706e-03\n",
      "  2.36873783e-01 4.87424652e-02]\n",
      " [5.02253386e-04 2.22639873e-01 5.52571143e-02 ... 3.00319451e-02\n",
      "  7.14566652e-02 3.20993338e-02]]\n",
      "Pred:  [[4.24564796e-03 3.37316276e-03 1.42509979e-03 ... 9.39506679e-01\n",
      "  7.03342605e-04 1.66775279e-02]\n",
      " [1.47152883e-02 1.55108653e-03 9.08907798e-03 ... 8.81238429e-04\n",
      "  5.87343480e-03 9.20420462e-03]\n",
      " [7.17908068e-03 1.62521507e-02 2.05540244e-02 ... 3.36783127e-03\n",
      "  7.28659361e-01 6.29599505e-02]\n",
      " ...\n",
      " [5.23459729e-02 2.17953922e-04 1.63660912e-02 ... 3.40066928e-05\n",
      "  2.51293377e-02 1.10694031e-02]\n",
      " [1.32161150e-02 4.64409717e-04 1.27000233e-03 ... 5.71338489e-03\n",
      "  2.30943954e-01 3.02025553e-02]\n",
      " [2.50712124e-04 2.15944613e-01 4.30927208e-02 ... 2.25496129e-02\n",
      "  7.99968929e-02 1.97603105e-02]]\n",
      "Pred:  [[3.08502073e-03 1.99824997e-03 8.83201365e-04 ... 9.56130388e-01\n",
      "  5.54450702e-04 1.08938983e-02]\n",
      " [1.18876338e-02 8.72070455e-04 5.46204065e-03 ... 5.11619179e-04\n",
      "  3.86833094e-03 7.21890349e-03]\n",
      " [5.66132202e-03 1.01985987e-02 1.70910999e-02 ... 2.12431660e-03\n",
      "  7.59231828e-01 4.51280890e-02]\n",
      " ...\n",
      " [4.92637244e-02 1.26003067e-04 1.36539862e-02 ... 1.62938633e-05\n",
      "  2.14256336e-02 7.06325334e-03]\n",
      " [8.42140646e-03 2.21524363e-04 9.39333798e-04 ... 4.39844054e-03\n",
      "  2.19105937e-01 2.00085388e-02]\n",
      " [1.34455145e-04 2.07937502e-01 3.50714905e-02 ... 1.80848294e-02\n",
      "  9.33020396e-02 1.30596521e-02]]\n",
      "Pred:  [[2.32613874e-03 1.23688792e-03 5.75892617e-04 ... 9.65015940e-01\n",
      "  5.06398323e-04 7.58526836e-03]\n",
      " [9.59804482e-03 5.53352042e-04 3.59325739e-03 ... 3.05693323e-04\n",
      "  2.92810688e-03 5.89616558e-03]\n",
      " [4.51796809e-03 6.63092772e-03 1.44311964e-02 ... 1.44165827e-03\n",
      "  7.87477196e-01 3.27830758e-02]\n",
      " ...\n",
      " [4.46365536e-02 8.16917226e-05 1.16475586e-02 ... 8.34817051e-06\n",
      "  1.91009917e-02 4.73359435e-03]\n",
      " [5.48225713e-03 1.13708178e-04 7.50472028e-04 ... 3.47302100e-03\n",
      "  2.07816434e-01 1.42935172e-02]\n",
      " [7.60108755e-05 2.01775605e-01 2.89029653e-02 ... 1.51028834e-02\n",
      "  1.13029466e-01 9.21365848e-03]]\n",
      "Pred:  [[1.79255457e-03 8.05491808e-04 3.86207688e-04 ... 9.70625810e-01\n",
      "  5.15004812e-04 5.56842784e-03]\n",
      " [7.67696190e-03 3.84170688e-04 2.58121415e-03 ... 1.91106611e-04\n",
      "  2.47996468e-03 5.00093758e-03]\n",
      " [3.62211631e-03 4.53185020e-03 1.24047951e-02 ... 1.03791696e-03\n",
      "  8.16109660e-01 2.42555591e-02]\n",
      " ...\n",
      " [3.87618171e-02 5.76571726e-05 1.01359154e-02 ... 4.51732656e-06\n",
      "  1.79745096e-02 3.26586023e-03]\n",
      " [3.68208447e-03 6.23129877e-05 6.31975099e-04 ... 2.78842010e-03\n",
      "  2.00241813e-01 1.08478768e-02]\n",
      " [4.53044350e-05 1.97464612e-01 2.34511326e-02 ... 1.28592516e-02\n",
      "  1.41650502e-01 6.84276207e-03]]\n",
      "Pred:  [[1.40412879e-03 5.51960048e-04 2.65668759e-04 ... 9.74768059e-01\n",
      "  5.54574478e-04 4.24406083e-03]\n",
      " [6.06651657e-03 2.85938130e-04 1.98816661e-03 ... 1.25942558e-04\n",
      "  2.27921307e-03 4.40885972e-03]\n",
      " [2.90576388e-03 3.25936444e-03 1.08583219e-02 ... 7.88096427e-04\n",
      "  8.43799625e-01 1.82723452e-02]\n",
      " ...\n",
      " [3.24482509e-02 4.32810438e-05 8.98455934e-03 ... 2.55904844e-06\n",
      "  1.77070668e-02 2.30094533e-03]\n",
      " [2.55962386e-03 3.62662425e-05 5.51098770e-04 ... 2.28587966e-03\n",
      "  1.94369693e-01 8.58164288e-03]\n",
      " [2.84056368e-05 1.94377590e-01 1.87362118e-02 ... 1.10049389e-02\n",
      "  1.79722972e-01 5.25622196e-03]]\n",
      "Pred:  [[1.11810229e-03 3.95935295e-04 1.88211457e-04 ... 9.78281166e-01\n",
      "  6.04312364e-04 3.30450363e-03]\n",
      " [4.75947590e-03 2.24220504e-04 1.62473113e-03 ... 8.74206569e-05\n",
      "  2.19387907e-03 3.98251398e-03]\n",
      " [2.32920882e-03 2.45940763e-03 9.61788553e-03 ... 6.26719260e-04\n",
      "  8.69168070e-01 1.38444953e-02]\n",
      " ...\n",
      " [2.64772795e-02 3.40209915e-05 8.09101198e-03 ... 1.50928295e-06\n",
      "  1.80696635e-02 1.63007029e-03]\n",
      " [1.83092230e-03 2.23053265e-05 4.92059130e-04 ... 1.91375574e-03\n",
      "  1.88278311e-01 6.85126307e-03]\n",
      " [1.85933869e-05 1.91985271e-01 1.48696729e-02 ... 9.41598023e-03\n",
      "  2.24689404e-01 4.09293297e-03]]\n",
      "Pred:  [[9.02495748e-04 2.96531601e-04 1.37059704e-04 ... 9.81555439e-01\n",
      "  6.43728527e-04 2.64490597e-03]\n",
      " [3.73654908e-03 1.82332624e-04 1.37077948e-03 ... 6.33783602e-05\n",
      "  2.14031409e-03 3.61125427e-03]\n",
      " [1.86964435e-03 1.94189224e-03 8.60808160e-03 ... 5.14958552e-04\n",
      "  8.91977615e-01 1.03672936e-02]\n",
      " ...\n",
      " [2.12806030e-02 2.76682609e-05 7.32669024e-03 ... 9.26659173e-07\n",
      "  1.89209705e-02 1.14192051e-03]\n",
      " [1.34401833e-03 1.44004831e-05 4.48502456e-04 ... 1.62479293e-03\n",
      "  1.82077878e-01 5.31966603e-03]\n",
      " [1.25859038e-05 1.90275067e-01 1.18641786e-02 ... 8.06062323e-03\n",
      "  2.71909856e-01 3.16260733e-03]]\n",
      "Pred:  [[7.34651274e-04 2.31222722e-04 1.02078211e-04 ... 9.84712787e-01\n",
      "  6.53742160e-04 2.21127994e-03]\n",
      " [2.94573143e-03 1.51843245e-04 1.14280298e-03 ... 4.74094835e-05\n",
      "  2.07180031e-03 3.23358169e-03]\n",
      " [1.50351064e-03 1.60302278e-03 7.83049807e-03 ... 4.29653640e-04\n",
      "  9.12221018e-01 7.64617902e-03]\n",
      " ...\n",
      " [1.69708200e-02 2.30122404e-05 6.56827518e-03 ... 5.94511587e-07\n",
      "  2.02129824e-02 7.87501723e-04]\n",
      " [1.01310707e-03 9.67983613e-06 4.17063024e-04 ... 1.38498319e-03\n",
      "  1.76377963e-01 3.94049749e-03]\n",
      " [8.73612833e-06 1.89418664e-01 9.64252141e-03 ... 6.93446009e-03\n",
      "  3.17907756e-01 2.39921510e-03]]\n",
      "Pred:  [[6.04454230e-04 1.85847588e-04 7.77115286e-05 ... 9.87588188e-01\n",
      "  6.32864262e-04 1.93528504e-03]\n",
      " [2.33740417e-03 1.28691778e-04 9.33024501e-04 ... 3.63011903e-05\n",
      "  1.97868668e-03 2.84730713e-03]\n",
      " [1.21497698e-03 1.37812028e-03 7.24408306e-03 ... 3.60642036e-04\n",
      "  9.30103594e-01 5.62007907e-03]\n",
      " ...\n",
      " [1.35667522e-02 1.94137593e-05 5.80868308e-03 ... 3.98631980e-07\n",
      "  2.20913920e-02 5.40095349e-04]\n",
      " [7.85461432e-04 6.72183969e-06 3.96208488e-04 ... 1.17851256e-03\n",
      "  1.72430414e-01 2.79834126e-03]\n",
      " [6.21689311e-06 1.89119909e-01 7.99454538e-03 ... 6.00704240e-03\n",
      "  3.64006988e-01 1.79275502e-03]]\n",
      "Pred:  [[5.06778374e-04 1.51783419e-04 6.05374098e-05 ... 9.89910421e-01\n",
      "  6.01297521e-04 1.74620872e-03]\n",
      " [1.87544541e-03 1.10797463e-04 7.62974020e-04 ... 2.82638735e-05\n",
      "  1.87693960e-03 2.47398042e-03]\n",
      " [9.93080651e-04 1.22070803e-03 6.76377255e-03 ... 3.04407711e-04\n",
      "  9.45895521e-01 4.18670073e-03]\n",
      " ...\n",
      " [1.09789660e-02 1.65379908e-05 5.11067662e-03 ... 2.76890731e-07\n",
      "  2.47545976e-02 3.72811467e-04]\n",
      " [6.26992791e-04 4.78250739e-06 3.85647924e-04 ... 1.00050914e-03\n",
      "  1.71993267e-01 1.95947038e-03]\n",
      " [4.56755561e-06 1.88747759e-01 6.70201409e-03 ... 5.20243849e-03\n",
      "  4.16984712e-01 1.33778051e-03]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:  [[4.35640352e-04 1.24642190e-04 4.81329187e-05 ... 9.91601411e-01\n",
      "  5.85797013e-04 1.59257548e-03]\n",
      " [1.52768518e-03 9.67441739e-05 6.35215910e-04 ... 2.21817015e-05\n",
      "  1.79209233e-03 2.13499504e-03]\n",
      " [8.23775222e-04 1.09993580e-03 6.31769076e-03 ... 2.57543460e-04\n",
      "  9.59429953e-01 3.20137865e-03]\n",
      " ...\n",
      " [9.01528084e-03 1.41909618e-05 4.53178489e-03 ... 1.97139429e-07\n",
      "  2.82878610e-02 2.59868659e-04]\n",
      " [5.14061329e-04 3.46113265e-06 3.84857906e-04 ... 8.46929854e-04\n",
      "  1.76328274e-01 1.40633360e-03]\n",
      " [3.48893377e-06 1.87684254e-01 5.64693644e-03 ... 4.45314030e-03\n",
      "  4.86004958e-01 1.00889975e-03]]\n",
      "Pred:  [[3.84166365e-04 1.02735472e-04 3.87885102e-05 ... 9.92773205e-01\n",
      "  5.96132754e-04 1.45468938e-03]\n",
      " [1.26533513e-03 8.54743954e-05 5.38486757e-04 ... 1.74864514e-05\n",
      "  1.72413120e-03 1.84627544e-03]\n",
      " [6.94131204e-04 9.98126192e-04 5.88527139e-03 ... 2.18160989e-04\n",
      "  9.69805010e-01 2.51145583e-03]\n",
      " ...\n",
      " [7.50388509e-03 1.22295817e-05 4.07394198e-03 ... 1.42902053e-07\n",
      "  3.25158516e-02 1.82829708e-04]\n",
      " [4.31651166e-04 2.53605723e-06 3.91965942e-04 ... 7.15062031e-04\n",
      "  1.84315318e-01 1.04946817e-03]\n",
      " [2.77063999e-06 1.85692767e-01 4.78626791e-03 ... 3.74945766e-03\n",
      "  5.70121770e-01 7.72337193e-04]]\n",
      "Pred:  [[3.46276055e-04 8.51907357e-05 3.14563432e-05 ... 9.93600629e-01\n",
      "  6.21216621e-04 1.33181497e-03]\n",
      " [1.06580930e-03 7.61219950e-05 4.61079131e-04 ... 1.39078287e-05\n",
      "  1.62844438e-03 1.60542903e-03]\n",
      " [5.93750375e-04 9.08014102e-04 5.47510070e-03 ... 1.85945119e-04\n",
      "  9.76744229e-01 2.00625842e-03]\n",
      " ...\n",
      " [6.32034343e-03 1.05565120e-05 3.69821042e-03 ... 1.05254990e-07\n",
      "  3.66321328e-02 1.30205440e-04]\n",
      " [3.70462433e-04 1.87782364e-06 4.03161776e-04 ... 6.04874102e-04\n",
      "  1.92632568e-01 8.11475772e-04]\n",
      " [2.26592335e-06 1.82927628e-01 4.10571128e-03 ... 3.12539119e-03\n",
      "  6.52467396e-01 6.00354720e-04]]\n",
      "Pred:  [[3.17434972e-04 7.12501086e-05 2.55533115e-05 ... 9.94229718e-01\n",
      "  6.40949482e-04 1.22234185e-03]\n",
      " [9.12041958e-04 6.80636928e-05 3.96254545e-04 ... 1.12173404e-05\n",
      "  1.46759311e-03 1.40946602e-03]\n",
      " [5.14495396e-04 8.27789550e-04 5.10031723e-03 ... 1.59977484e-04\n",
      "  9.80906649e-01 1.62739514e-03]\n",
      " ...\n",
      " [5.37781622e-03 9.10899793e-06 3.36870593e-03 ... 7.88110594e-08\n",
      "  3.92289334e-02 9.43447361e-05]\n",
      " [3.24589737e-04 1.40313457e-06 4.13851785e-04 ... 5.15636247e-04\n",
      "  1.96786930e-01 6.49872374e-04]\n",
      " [1.88507689e-06 1.79736853e-01 3.59596186e-03 ... 2.60410310e-03\n",
      "  7.15520131e-01 4.73553574e-04]]\n",
      "Pred:  [[2.94545601e-04 6.02716598e-05 2.07494661e-05 ... 9.94745104e-01\n",
      "  6.39205179e-04 1.12302991e-03]\n",
      " [7.92900449e-04 6.09069492e-05 3.41655668e-04 ... 9.19687154e-06\n",
      "  1.25343980e-03 1.25785604e-03]\n",
      " [4.51161572e-04 7.57079274e-04 4.76909776e-03 ... 1.38632970e-04\n",
      "  9.83211638e-01 1.34080544e-03]\n",
      " ...\n",
      " [4.61667089e-03 7.84744645e-06 3.06591798e-03 ... 6.00063995e-08\n",
      "  3.94470256e-02 6.97719282e-05]\n",
      " [2.90421023e-04 1.05733360e-06 4.21089236e-04 ... 4.44216832e-04\n",
      "  1.93743157e-01 5.38332280e-04]\n",
      " [1.58184247e-06 1.76395757e-01 3.24204792e-03 ... 2.18260094e-03\n",
      "  7.53706034e-01 3.78218120e-04]]\n",
      "Pred:  [[2.75643251e-04 5.16511171e-05 1.68356794e-05 ... 9.95185983e-01\n",
      "  6.17546298e-04 1.03198370e-03]\n",
      " [7.01485976e-04 5.44075424e-05 2.96384883e-04 ... 7.65417913e-06\n",
      "  1.03976994e-03 1.14569557e-03]\n",
      " [4.00277577e-04 6.95279036e-04 4.48131350e-03 ... 1.20071825e-04\n",
      "  9.84656905e-01 1.12109740e-03]\n",
      " ...\n",
      " [3.98773214e-03 6.75269076e-06 2.78324438e-03 ... 4.64192882e-08\n",
      "  3.80046118e-02 5.26696040e-05]\n",
      " [2.65393717e-04 8.03568075e-07 4.24735814e-04 ... 3.86251828e-04\n",
      "  1.84644371e-01 4.57660400e-04]\n",
      " [1.33630777e-06 1.72790038e-01 3.02002118e-03 ... 1.83959476e-03\n",
      "  7.73954662e-01 3.05161831e-04]]\n",
      "Pred:  [[2.59561984e-04 4.47498970e-05 1.36711258e-05 ... 9.95574093e-01\n",
      "  5.83864283e-04 9.47552495e-04]\n",
      " [6.31804135e-04 4.84373988e-05 2.58969189e-04 ... 6.45390787e-06\n",
      "  8.66685917e-04 1.06278400e-03]\n",
      " [3.58578031e-04 6.40260676e-04 4.23043359e-03 ... 1.03167074e-04\n",
      "  9.85925058e-01 9.47113095e-04]\n",
      " ...\n",
      " [3.44682674e-03 5.81485475e-06 2.52493013e-03 ... 3.64224360e-08\n",
      "  3.62999543e-02 4.05265158e-05]\n",
      " [2.47200423e-04 6.15458826e-07 4.26203415e-04 ... 3.38155868e-04\n",
      "  1.71957343e-01 3.94122032e-04]\n",
      " [1.13760805e-06 1.68565498e-01 2.90528921e-03 ... 1.55294095e-03\n",
      "  7.86441118e-01 2.48071327e-04]]\n",
      "Pred:  [[2.45839945e-04 3.89914106e-05 1.11501014e-05 ... 9.95927934e-01\n",
      "  5.38584558e-04 8.65416156e-04]\n",
      " [5.77985207e-04 4.29980059e-05 2.27624350e-04 ... 5.51656807e-06\n",
      "  7.34341860e-04 9.95029778e-04]\n",
      " [3.22758350e-04 5.89171375e-04 4.00464255e-03 ... 8.77605422e-05\n",
      "  9.87112498e-01 8.02092600e-04]\n",
      " ...\n",
      " [2.97300270e-03 5.01986356e-06 2.30496238e-03 ... 2.89419319e-08\n",
      "  3.49531815e-02 3.17404420e-05]\n",
      " [2.33456261e-04 4.74615992e-07 4.26439506e-04 ... 2.97596477e-04\n",
      "  1.56531115e-01 3.39240153e-04]\n",
      " [9.75991763e-07 1.63608232e-01 2.88095830e-03 ... 1.30950296e-03\n",
      "  7.96576393e-01 2.01929757e-04]]\n",
      "Pred:  [[2.34592742e-04 3.40242265e-05 9.15964309e-06 ... 9.96255585e-01\n",
      "  4.84241526e-04 7.80394758e-04]\n",
      " [5.35206988e-04 3.81989426e-05 2.00993240e-04 ... 4.77844028e-06\n",
      "  6.28259048e-04 9.30507269e-04]\n",
      " [2.90275019e-04 5.39932216e-04 3.78108403e-03 ... 7.39605704e-05\n",
      "  9.88100532e-01 6.77012145e-04]\n",
      " ...\n",
      " [2.57373034e-03 4.34732693e-06 2.14391511e-03 ... 2.32618046e-08\n",
      "  3.37134334e-02 2.52405193e-05]\n",
      " [2.22134914e-04 3.68651698e-07 4.24434806e-04 ... 2.62418600e-04\n",
      "  1.39794925e-01 2.89083079e-04]\n",
      " [8.43778020e-07 1.58146584e-01 2.93702336e-03 ... 1.10157991e-03\n",
      "  8.05083717e-01 1.63238584e-04]]\n",
      "Pred:  [[2.25948912e-04 2.96880172e-05 7.59078068e-06 ... 9.96560508e-01\n",
      "  4.29898860e-04 6.91641503e-04]\n",
      " [4.99705276e-04 3.41242472e-05 1.78355779e-04 ... 4.18099400e-06\n",
      "  5.41762959e-04 8.63916491e-04]\n",
      " [2.60309348e-04 4.90893602e-04 3.52812670e-03 ... 6.17854066e-05\n",
      "  9.88921330e-01 5.70326060e-04]\n",
      " ...\n",
      " [2.25137849e-03 3.77476513e-06 2.06657018e-03 ... 1.88775854e-08\n",
      "  3.22511522e-02 2.02860905e-05]\n",
      " [2.12616477e-04 2.88662812e-07 4.17033641e-04 ... 2.30788307e-04\n",
      "  1.24466754e-01 2.43193647e-04]\n",
      " [7.35062565e-07 1.52480090e-01 3.06853886e-03 ... 9.24469416e-04\n",
      "  8.11881528e-01 1.30712704e-04]]\n",
      "Pred:  [[2.19982513e-04 2.58997729e-05 6.36050888e-06 ... 9.96852920e-01\n",
      "  3.83091451e-04 6.04986002e-04]\n",
      " [4.69173836e-04 3.07870271e-05 1.59415919e-04 ... 3.68934057e-06\n",
      "  4.72790893e-04 7.96937314e-04]\n",
      " [2.32984543e-04 4.42339067e-04 3.24290016e-03 ... 5.13933961e-05\n",
      "  9.89675610e-01 4.82117464e-04]\n",
      " ...\n",
      " [1.98669648e-03 3.29121192e-06 2.07742917e-03 ... 1.54645007e-08\n",
      "  3.06051622e-02 1.64334268e-05]\n",
      " [2.05696077e-04 2.28245029e-07 4.02081211e-04 ... 2.02196077e-04\n",
      "  1.11874526e-01 2.03346976e-04]\n",
      " [6.44166334e-07 1.47124652e-01 3.28318414e-03 ... 7.77189846e-04\n",
      "  8.17457418e-01 1.04217202e-04]]\n",
      "Pred:  [[2.16158286e-04 2.27104540e-05 5.37600478e-06 ... 9.97150084e-01\n",
      "  3.47737013e-04 5.27570800e-04]\n",
      " [4.41765223e-04 2.83401751e-05 1.43335045e-04 ... 3.26362172e-06\n",
      "  4.17788782e-04 7.29683198e-04]\n",
      " [2.05883572e-04 4.02505881e-04 2.95285926e-03 ... 4.29880679e-05\n",
      "  9.90383403e-01 4.09310572e-04]\n",
      " ...\n",
      " [1.75325083e-03 2.90372807e-06 2.12036025e-03 ... 1.28511205e-08\n",
      "  2.91081935e-02 1.33847877e-05]\n",
      " [2.00493511e-04 1.85040039e-07 3.78532137e-04 ... 1.78081096e-04\n",
      "  1.01514824e-01 1.71993985e-04]\n",
      " [5.64106198e-07 1.43627826e-01 3.59056867e-03 ... 6.59999716e-04\n",
      "  8.22692114e-01 8.30741808e-05]]\n",
      "Pred:  [[2.14044484e-04 1.99559194e-05 4.60718181e-06 ... 9.97420870e-01\n",
      "  3.24408099e-04 4.64392340e-04]\n",
      " [4.13883042e-04 2.65340803e-05 1.31062911e-04 ... 2.88911051e-06\n",
      "  3.78182231e-04 6.66125251e-04]\n",
      " [1.81014210e-04 3.68971117e-04 2.68591399e-03 ... 3.63040116e-05\n",
      "  9.91022850e-01 3.51811797e-04]\n",
      " ...\n",
      " [1.54875086e-03 2.58256039e-06 2.11367844e-03 ... 1.08154082e-08\n",
      "  2.80927412e-02 1.09669819e-05]\n",
      " [1.95458672e-04 1.53267278e-07 3.50436805e-04 ... 1.58081231e-04\n",
      "  9.38662674e-02 1.47907760e-04]\n",
      " [4.95014670e-07 1.41425641e-01 3.95645064e-03 ... 5.66806852e-04\n",
      "  8.27610189e-01 6.60864256e-05]]\n",
      "Pred:  [[2.14279902e-04 1.74820735e-05 3.99286413e-06 ... 9.97647866e-01\n",
      "  3.08655681e-04 4.09132404e-04]\n",
      " [3.87648019e-04 2.48500314e-05 1.22483850e-04 ... 2.55990403e-06\n",
      "  3.52229264e-04 6.10094337e-04]\n",
      " [1.59901271e-04 3.39781704e-04 2.45656627e-03 ... 3.10147145e-05\n",
      "  9.91597752e-01 3.07094441e-04]\n",
      " ...\n",
      " [1.38637873e-03 2.30082172e-06 2.00595382e-03 ... 9.10931072e-09\n",
      "  2.75606725e-02 9.11833864e-06]\n",
      " [1.90065398e-04 1.27760208e-07 3.25177432e-04 ... 1.40523950e-04\n",
      "  8.92855863e-02 1.28684189e-04]\n",
      " [4.39036013e-07 1.38955608e-01 4.33416116e-03 ... 4.90089500e-04\n",
      "  8.32211991e-01 5.26353547e-05]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:  [[2.16212886e-04 1.52383391e-05 3.51768826e-06 ... 9.97842110e-01\n",
      "  2.96365996e-04 3.57358881e-04]\n",
      " [3.65812967e-04 2.31744364e-05 1.16530514e-04 ... 2.27839428e-06\n",
      "  3.34351185e-04 5.62210760e-04]\n",
      " [1.43662273e-04 3.11180902e-04 2.26341471e-03 ... 2.67804561e-05\n",
      "  9.92112091e-01 2.70769281e-04]\n",
      " ...\n",
      " [1.25925326e-03 2.04040503e-06 1.83888808e-03 ... 7.68913137e-09\n",
      "  2.71326606e-02 7.65811923e-06]\n",
      " [1.85969074e-04 1.06372088e-07 3.07242792e-04 ... 1.24976454e-04\n",
      "  8.66714703e-02 1.12956128e-04]\n",
      " [3.93733383e-07 1.35943525e-01 4.74536830e-03 ... 4.26198064e-04\n",
      "  8.36613924e-01 4.21808799e-05]]\n",
      "Pred:  [[2.18875462e-04 1.32595495e-05 3.17089584e-06 ... 9.98012850e-01\n",
      "  2.85759586e-04 3.08695370e-04]\n",
      " [3.48672654e-04 2.16229186e-05 1.12071032e-04 ... 2.03600108e-06\n",
      "  3.21715334e-04 5.22363421e-04]\n",
      " [1.31725868e-04 2.83146732e-04 2.09351426e-03 ... 2.33591803e-05\n",
      "  9.92556575e-01 2.40610117e-04]\n",
      " ...\n",
      " [1.15856783e-03 1.80038387e-06 1.67231408e-03 ... 6.50226291e-09\n",
      "  2.66253882e-02 6.48817977e-06]\n",
      " [1.83005317e-04 8.86365391e-08 2.98808714e-04 ... 1.11164035e-04\n",
      "  8.56318271e-02 9.99268336e-05]\n",
      " [3.57185731e-07 1.32500267e-01 5.25759105e-03 ... 3.73493676e-04\n",
      "  8.40819703e-01 3.41027656e-05]]\n",
      "Pred:  [[2.21488696e-04 1.16441679e-05 2.91990226e-06 ... 9.98160518e-01\n",
      "  2.76319057e-04 2.66648170e-04]\n",
      " [3.34135825e-04 2.03705885e-05 1.07544718e-04 ... 1.82393073e-06\n",
      "  3.09412298e-04 4.91968898e-04]\n",
      " [1.22932134e-04 2.59436516e-04 1.92394664e-03 ... 2.05539868e-05\n",
      "  9.92931514e-01 2.18027705e-04]\n",
      " ...\n",
      " [1.07616625e-03 1.60357343e-06 1.52804320e-03 ... 5.51993518e-09\n",
      "  2.61271887e-02 5.61025354e-06]\n",
      " [1.79828387e-04 7.48524539e-08 2.96571322e-04 ... 9.86131477e-05\n",
      "  8.53721886e-02 9.00492713e-05]\n",
      " [3.29103858e-07 1.28122649e-01 5.95450765e-03 ... 3.30807493e-04\n",
      "  8.45427604e-01 2.82144255e-05]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ad7e61c394fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# train the ANN model with training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mhybrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-aed59844d432>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, y, epochs, lr)\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;31m# print('layer out delta  \\n', output.layer_delta.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                 \u001b[1;31m# print('layer1 delta  \\n', layer1.layer_delta.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-81e064cbcd51>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, delta_in, weights_in, targets, output_layer)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdel_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_output\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-81e064cbcd51>\u001b[0m in \u001b[0;36mdel_activation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mdel_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mActivation_Sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdel_layer_output\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdel_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdel_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-f3e5ea740c38>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mActivation_Sigmoid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# set other hyperparameters\n",
    "batch_size = 10\n",
    "epochs = 200\n",
    "lr = 1.0\n",
    "\n",
    "# configure the layers\n",
    "hidden = Layer_Dense(784,200)\n",
    "output = Layer_Dense(200,10)\n",
    "\n",
    "# create an ANN model\n",
    "hybrid = Hybrid(output, hidden, batch_size)\n",
    "\n",
    "# train the ANN model with training data\n",
    "hybrid.train(X_train, y_train, epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
